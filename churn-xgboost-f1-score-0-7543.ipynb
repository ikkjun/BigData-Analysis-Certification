{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Package Import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom xgboost import XGBClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-05T03:49:53.465303Z","iopub.execute_input":"2022-12-05T03:49:53.465792Z","iopub.status.idle":"2022-12-05T03:49:53.478428Z","shell.execute_reply.started":"2022-12-05T03:49:53.465754Z","shell.execute_reply":"2022-12-05T03:49:53.476909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Load","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/churn-modelling/Churn_Modelling.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:32.059164Z","iopub.execute_input":"2022-12-05T04:34:32.059639Z","iopub.status.idle":"2022-12-05T04:34:32.088001Z","shell.execute_reply.started":"2022-12-05T04:34:32.059605Z","shell.execute_reply":"2022-12-05T04:34:32.086583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 3.1. EDA","metadata":{}},{"cell_type":"code","source":"X = df.drop('Exited', axis=1)\ny = df[['Exited']]\n\ndata = [X, y]\nfor datum in data:\n    print(datum.head())\n    print()\n    print(datum.isnull().sum())\n    print()\n    print(datum.describe())\n    print()\n    print(datum.info())\n    print()\n    print(datum.corr())\n    print()\n    print(datum.columns)\n    print('*  ' * 30)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:32.580035Z","iopub.execute_input":"2022-12-05T04:34:32.580922Z","iopub.status.idle":"2022-12-05T04:34:32.673191Z","shell.execute_reply.started":"2022-12-05T04:34:32.580870Z","shell.execute_reply":"2022-12-05T04:34:32.671746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del_cols = ['RowNumber', 'CustomerId', 'Surname']\nnum_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\ncat_cols = ['Geography', 'Gender', 'NumOfProducts', 'HasCrCard', 'IsActiveMember']\ny_col = ['Exited']","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:42.020972Z","iopub.execute_input":"2022-12-05T04:34:42.022642Z","iopub.status.idle":"2022-12-05T04:34:42.030367Z","shell.execute_reply.started":"2022-12-05T04:34:42.022578Z","shell.execute_reply":"2022-12-05T04:34:42.028746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Detect Outliers","metadata":{}},{"cell_type":"code","source":"train = pd.concat([X, y], axis=1)\n\ndef Counter(x):\n    Dict = {}\n    for y in x:\n        if y in Dict:\n            Dict[y] +=1\n        else:\n            Dict[y] = 1\n    return Dict\n\ndef detect_outliers(df, n, features):\n    outlier_indices = []\n    for col in features:\n        q1 = np.percentile(df[col], 25)\n        q3 = np.percentile(df[col], 75)\n        iqr = q3 - q1\n        outlier_step = iqr * 1.5\n        outlier_rows = df[(df[col] < q1 - outlier_step)|(df[col] > q3 + outlier_step)].index\n        outlier_indices.extend(outlier_rows)\n    outlier_indices = Counter(outlier_indices)\n    multi_outliers = list(k for k, v in outlier_indices.items() if v >= n)\n    return multi_outliers\n\ntrain = train.drop(detect_outliers(train, 1, num_cols)).reset_index(drop=True)\nprint(X.shape, train.shape)\n\nX_train = train.iloc[:,:-1]\ny_train = train.iloc[:,-1:]","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:42.500295Z","iopub.execute_input":"2022-12-05T04:34:42.500868Z","iopub.status.idle":"2022-12-05T04:34:42.535046Z","shell.execute_reply.started":"2022-12-05T04:34:42.500821Z","shell.execute_reply":"2022-12-05T04:34:42.533684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Encoding","metadata":{}},{"cell_type":"code","source":"X_train.Gender = X_train.Gender.str.lstrip().str.lower()\nfor col in cat_cols:\n    print(X_train[col].unique())\n\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(X[cat_cols])\nX_train_enc = pd.DataFrame(enc.transform(X_train[cat_cols]).toarray(), columns = enc.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:45.028312Z","iopub.execute_input":"2022-12-05T04:34:45.028859Z","iopub.status.idle":"2022-12-05T04:34:45.073272Z","shell.execute_reply.started":"2022-12-05T04:34:45.028818Z","shell.execute_reply":"2022-12-05T04:34:45.071762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Set Split","metadata":{}},{"cell_type":"code","source":"X = pd.concat([X_train[num_cols], X_train_enc], axis=1)\ny = y_train[y_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:46.003114Z","iopub.execute_input":"2022-12-05T04:34:46.003644Z","iopub.status.idle":"2022-12-05T04:34:46.061280Z","shell.execute_reply.started":"2022-12-05T04:34:46.003603Z","shell.execute_reply":"2022-12-05T04:34:46.060051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Data Scaling","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train[num_cols])\nX_train[num_cols] = scaler.transform(X_train[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:47.618597Z","iopub.execute_input":"2022-12-05T04:34:47.619597Z","iopub.status.idle":"2022-12-05T04:34:47.639799Z","shell.execute_reply.started":"2022-12-05T04:34:47.619547Z","shell.execute_reply":"2022-12-05T04:34:47.638335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Data Modeling","metadata":{}},{"cell_type":"code","source":"rf1 = RandomForestClassifier(max_depth=2, random_state=0, n_jobs=-1)\nrf1.fit(X_train, y_train.values.ravel())\nrf1_pred = rf1.predict(X_test)\n\nxgb1 = XGBClassifier(random_state=0, n_jobs=-1)\nxgb1.fit(X_train, y_train)\nxgb1_pred = xgb1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:48.019481Z","iopub.execute_input":"2022-12-05T04:34:48.020156Z","iopub.status.idle":"2022-12-05T04:34:49.224435Z","shell.execute_reply.started":"2022-12-05T04:34:48.020118Z","shell.execute_reply":"2022-12-05T04:34:49.223308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Model Score","metadata":{}},{"cell_type":"code","source":"rf1_score = f1_score(y_test, rf1_pred, average = 'macro')\nxgb1_score = f1_score(y_test, xgb1_pred, average = 'macro')\nprint(f'Before Tuning -> random forest score: {rf1_score}, xgboost score: {xgb1_score}')","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:49.226873Z","iopub.execute_input":"2022-12-05T04:34:49.227796Z","iopub.status.idle":"2022-12-05T04:34:49.243499Z","shell.execute_reply.started":"2022-12-05T04:34:49.227737Z","shell.execute_reply":"2022-12-05T04:34:49.242055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Hyper Parameter tuning","metadata":{}},{"cell_type":"code","source":"rf1_parameters = {\n    'max_depth':[2,4,8], \n    'min_samples_leaf': [1,2,3],\n    'min_samples_split': [2,4,6],\n    'n_estimators': [100,500,1000]\n    }\nrf1_cv = GridSearchCV(rf1, rf1_parameters, scoring = 'f1_macro', cv=5)\nrf1_cv.fit(X_train, y_train.values.ravel())\nprint(rf1_cv.best_params_)\n\nxgb1_parameters = {\n    'colsample_bytree': [0.5, 1],\n    'learning_rate': [0.1, 0.01, 0.2],\n    'max_depth': [3,6,9],\n    'n_estimators': [100,500,1000]\n}\nxgb1_cv = GridSearchCV(xgb1, xgb1_parameters, scoring = 'f1_macro', cv=5)\nxgb1_cv.fit(X_train, y_train)\nprint(xgb1_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:49:54.656309Z","iopub.execute_input":"2022-12-05T03:49:54.656951Z","iopub.status.idle":"2022-12-05T04:13:47.057182Z","shell.execute_reply.started":"2022-12-05T03:49:54.656888Z","shell.execute_reply":"2022-12-05T04:13:47.055954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf2 = RandomForestClassifier(max_depth=8, min_samples_leaf=1, min_samples_split=2, n_estimators=100, random_state=0, n_jobs=-1)\nclf2.fit(X_train, y_train.values.ravel())\nclf2_pred = clf2.predict(X_test)\nclf2_score = f1_score(y_test, clf2_pred, average = 'macro')\n\nxgb2 = XGBClassifier(colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, random_state=0, n_jobs=-1)\nxgb2.fit(X_train, y_train)\nxgb2_pred = xgb2.predict(X_test)\nxgb2_score = f1_score(y_test, xgb2_pred, average = 'macro')\nprint(f'After Tuning -> random forest score: {clf2_score}, xgboost score: {xgb2_score}')","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:34:53.704138Z","iopub.execute_input":"2022-12-05T04:34:53.704551Z","iopub.status.idle":"2022-12-05T04:34:55.663679Z","shell.execute_reply.started":"2022-12-05T04:34:53.704519Z","shell.execute_reply":"2022-12-05T04:34:55.662770Z"},"trusted":true},"execution_count":null,"outputs":[]}]}